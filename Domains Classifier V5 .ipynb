{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NLP Exploration 2: Webscraping \n",
    "This exploration is an extension of **Domains Classifier V4**. We looked at just the domain name in that example, and utilized segmentation and a few other things in order to create a **vocabulary** of words that occur in the domain name. This vocabulary then one hot encoded in order to represent inputs, and then these inputs were fed into a **random forest** in order to try and map to the correct output class. \n",
    "\n",
    "We are now going to try and extended that by making use of **Webscraping**. Working with the same data set we will scrape the associated webpages and try to gather as much information as we can that may help us make predictions. Some things to note:\n",
    "1. We will start by just looking at the home page. This clearly does not give us 100% of the information we may need, but it will be the first iteration.\n",
    "2. We will also only be looking at visible text and not at css class names, commented out code, or anything else that would not be visible to a user. \n",
    "2. Based on the number of domains we have scores for (2000) we will need to be wary of how large we let our vocabulary size grow to. \n",
    "\n",
    "With that said, the first step is for us to actually scrape the home page of each domain. We can start by importing our necessary modules and loading in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from util import (preprocess_analyst_scored_domains, class_imbalance)\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn Plot Styling\n",
    "sns.set(style=\"white\", palette=\"husl\")\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>analystResult</th>\n",
       "      <th>BellonaStatus</th>\n",
       "      <th>medianLoadTime</th>\n",
       "      <th>speedPercentile</th>\n",
       "      <th>trafficDataRank</th>\n",
       "      <th>trafficDataReachRank</th>\n",
       "      <th>reachPerMillionValue</th>\n",
       "      <th>pageViewsPerMillionValue</th>\n",
       "      <th>pageViewsRankValue</th>\n",
       "      <th>usageStatisticRankValue</th>\n",
       "      <th>reachRankValue</th>\n",
       "      <th>historyDataScore</th>\n",
       "      <th>domainAge</th>\n",
       "      <th>registrantContactCountry</th>\n",
       "      <th>privateRegistrationStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07449m.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>{\"registrantName\":\"Domain Administrator\",\"simi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037kissfm.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6955.0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041kqth.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TODO</td>\n",
       "      <td>7687.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1941173.0</td>\n",
       "      <td>1872730.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2322074.0</td>\n",
       "      <td>2025813.0</td>\n",
       "      <td>2060156.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049maxcountry.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1053thebuzz.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6221.0</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               domain analystResult BellonaStatus  medianLoadTime  \\\n",
       "0          07449m.com           NaN           NaN             NaN   \n",
       "1      1037kissfm.com           NaN           NaN             NaN   \n",
       "2        1041kqth.com           NaN          TODO          7687.0   \n",
       "3  1049maxcountry.com           NaN           NaN             NaN   \n",
       "4     1053thebuzz.com           NaN           NaN             NaN   \n",
       "\n",
       "   speedPercentile  trafficDataRank  trafficDataReachRank  \\\n",
       "0              NaN              NaN                   NaN   \n",
       "1              NaN              NaN                   NaN   \n",
       "2              1.0        1941173.0             1872730.0   \n",
       "3              NaN              NaN                   NaN   \n",
       "4              NaN              NaN                   NaN   \n",
       "\n",
       "  reachPerMillionValue pageViewsPerMillionValue  pageViewsRankValue  \\\n",
       "0                  NaN                      NaN                 NaN   \n",
       "1                  NaN                      NaN                 NaN   \n",
       "2                  0.2                     0.01           2322074.0   \n",
       "3                  NaN                      NaN                 NaN   \n",
       "4                  NaN                      NaN                 NaN   \n",
       "\n",
       "   usageStatisticRankValue  reachRankValue  historyDataScore  domainAge  \\\n",
       "0                      NaN             NaN                 3       68.0   \n",
       "1                      NaN             NaN                 3     6955.0   \n",
       "2                2025813.0       2060156.0                 3     1251.0   \n",
       "3                      NaN             NaN                 3      978.0   \n",
       "4                      NaN             NaN                 3     6221.0   \n",
       "\n",
       "  registrantContactCountry                          privateRegistrationStatus  \n",
       "0            UNITED STATES  {\"registrantName\":\"Domain Administrator\",\"simi...  \n",
       "1            UNITED STATES                                                NaN  \n",
       "2            UNITED STATES                                                NaN  \n",
       "3            UNITED STATES                                                NaN  \n",
       "4            UNITED STATES                                                NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our data\n",
    "df = pd.read_csv('PPSDomains.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>analystResult</th>\n",
       "      <th>domainAge</th>\n",
       "      <th>registrantContactCountry</th>\n",
       "      <th>privateRegistrationStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10thousandcouples.com</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.298104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1170kfaq.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11alive.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1.205884</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>120gdyiyuan.com</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.361280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12news.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1.117373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   domain  analystResult  domainAge  registrantContactCountry  \\\n",
       "10  10thousandcouples.com              0  -0.298104                         0   \n",
       "11           1170kfaq.com              0   0.575157                         1   \n",
       "12            11alive.com              0   1.205884                         1   \n",
       "13        120gdyiyuan.com              0  -1.361280                         1   \n",
       "14             12news.com              0   1.117373                         1   \n",
       "\n",
       "    privateRegistrationStatus  \n",
       "10                          0  \n",
       "11                          0  \n",
       "12                          0  \n",
       "13                          0  \n",
       "14                          0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call preprocess Utility Function\n",
    "analystScoredDomains = preprocess_analyst_scored_domains(df)\n",
    "analystScoredDomains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "## 1.1 Let the webscraping begin\n",
    "Okay now that our data has been loaded and preprocessed, we can begin the process of webscrapping. In order to do that we will make use of the `urllib` and `BeatifulSoup` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets go through the process of extracting the home page content for one domain, and then create functions to apply that to all of our domains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to take HTML and return only the visible text\n",
    "def text_from_html(body):\n",
    "  soup = BeautifulSoup(body, 'html.parser')\n",
    "  texts = soup.findAll(text=True)\n",
    "  visible_texts = filter(tag_visible, texts)\n",
    "  return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "# Function that determines whether the text would be visible on the web page\n",
    "def tag_visible(element):\n",
    "  if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "      return False\n",
    "  if isinstance(element, Comment):\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request the particular webpage\n",
    "html = urllib.request.urlopen('http://12news.com').read()\n",
    "\n",
    "# Get the page text from the html\n",
    "page_text = text_from_html(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to get the text in the format we want, we will utilize the `nltk` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Tokenize all of the page text\n",
    "page_text_tokens = nltk.word_tokenize(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WATCH', 'LIVE', 'On', 'Air', '3:55PM', '80', 'Phoenix', ',', 'AZ', 'Phoenix']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create new column for page content, set to an empty string\n",
    "analystScoredDomains['page_content'] = ''\n",
    "\n",
    "# Get index of our test example\n",
    "index = analystScoredDomains[analystScoredDomains['domain'] == '12news.com'].index[0]\n",
    "\n",
    "# Using .at accessor, set value of page_content column to be equal to page_text_tokens\n",
    "analystScoredDomains.at[index, 'page_content'] = page_text_tokens\n",
    "\n",
    "# Display first ten values, and then the total length of the array\n",
    "display(analystScoredDomains.at[index, 'page_content'][:10])\n",
    "display(len(analystScoredDomains.at[index, 'page_content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, so we did it for one entry, let's create a function that does this process for us. We also are going to want to ensure that we peform the necessary text processing. To do that we will create a tokenizer function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))         # grab stop words \n",
    "\n",
    "# Create Custom tokenizer function \n",
    "def custom_tokenizer(s):\n",
    "  s = s.lower()\n",
    "  tokens = nltk.tokenize.word_tokenize(s)                        # essentially string.split()\n",
    "  tokens = [t for t in tokens if len(t) > 2]                     # get rid of short words\n",
    "  tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]     # get words to base form\n",
    "  tokens = [t for t in tokens if t not in stopwords]\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have all of the functions we need, it is time to make all of our requests, scrape the pages, and set the values for `page_content` in our dataframe. We also want to index each word!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map = {}           # Vocabulary\n",
    "current_index = 0\n",
    "\n",
    "for index, row in analystScoredDomains.iterrows():\n",
    "  \n",
    "  try: \n",
    "    # Create full URL to make valid request\n",
    "    domain = analystScoredDomains.at[index, 'domain']\n",
    "    full_domain_request = 'http://' + domain\n",
    "\n",
    "    # Request the particular webpage\n",
    "    html = urllib.request.urlopen(full_domain_request).read()\n",
    "\n",
    "    # Get the page text from the html\n",
    "    page_text = text_from_html(html)\n",
    "\n",
    "    # Tokenize all of the page text\n",
    "    page_text_tokens = nltk.word_tokenize(page_text)\n",
    "    \n",
    "    # Using .at accessor, set value of page_content column to be equal to page_text_tokens\n",
    "    analystScoredDomains.at[index, 'page_content'] = page_text_tokens\n",
    "    \n",
    "#   except urllib.error.HTTPError as err: \n",
    "#     print('The request could not go through: ', )\n",
    "    \n",
    "#   except urllib.error.URLError as err: \n",
    "#     print('The request could not go through: ', )\n",
    "\n",
    "  except: \n",
    "    print(\"error occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
